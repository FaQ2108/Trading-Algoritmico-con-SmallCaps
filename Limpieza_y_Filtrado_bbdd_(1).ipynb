{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaQ2108/Trading-Algoritmico-con-SmallCaps/blob/main/Limpieza_y_Filtrado_bbdd_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlalchemy pymysql h5py google-colab\n",
        "\n",
        "from getpass import getpass  # Importar getpass para ocultar la entrada de la contraseña\n",
        "import pandas as pd\n",
        "import sqlalchemy as db\n",
        "from sqlalchemy.exc import SQLAlchemyError\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "class DatabaseAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.engine = None\n",
        "        self.cleaned_dataframes = {}\n",
        "\n",
        "    def get_db_connection(self):\n",
        "        try:\n",
        "            host = input(\"Introduce el host de la base de datos: \")\n",
        "            user = input(\"Introduce el usuario de la base de datos: \")\n",
        "            password = getpass(\"Introduce la contraseña de la base de datos: \")  # Oculta la contraseña\n",
        "            database = input(\"Introduce el nombre de la base de datos: \")\n",
        "\n",
        "            connection_string = f\"mysql+pymysql://{user}:{password}@{host}/{database}\"\n",
        "            self.engine = db.create_engine(connection_string)\n",
        "            print(\"Conexión establecida correctamente.\")\n",
        "            self.analyze_tables()\n",
        "        except SQLAlchemyError as e:\n",
        "            print(f\"Error al conectar a la base de datos: {e}\")\n",
        "\n",
        "    def count_nulls(self, df):\n",
        "        return df.isnull().sum()\n",
        "\n",
        "    def analyze_tables(self):\n",
        "        try:\n",
        "            # Proceso de limpieza para la tabla vista_datos_completos\n",
        "            query_vista = \"SELECT * FROM vista_datos_completos\"\n",
        "            df_vista = pd.read_sql(query_vista, self.engine)\n",
        "            print(\"Valores nulos antes de la limpieza (vista_datos_completos):\")\n",
        "            print(self.count_nulls(df_vista))\n",
        "\n",
        "            columns_to_check = df_vista.columns.difference(['spread', 'short_float'])\n",
        "            df_vista_cleaned = df_vista.dropna(subset=columns_to_check, how='any')\n",
        "\n",
        "            print(\"Valores nulos después de la limpieza (vista_datos_completos):\")\n",
        "            print(self.count_nulls(df_vista_cleaned))\n",
        "\n",
        "            # Aplicar el filtro adicional a vista_datos_completos\n",
        "            df_vista_cleaned = self.filter_vista_datos_completos(df_vista_cleaned)\n",
        "\n",
        "            # Proceso de limpieza para la tabla OHLCData\n",
        "            query_ohlc = \"SELECT * FROM OHLCData\"\n",
        "            df_ohlc = pd.read_sql(query_ohlc, self.engine)\n",
        "            print(\"Valores nulos antes de la limpieza (OHLCData):\")\n",
        "            print(self.count_nulls(df_ohlc))\n",
        "\n",
        "            # Limpiar nulos en OHLCData\n",
        "            df_ohlc_cleaned = df_ohlc.dropna()\n",
        "\n",
        "            print(\"Valores nulos después de la limpieza (OHLCData):\")\n",
        "            print(self.count_nulls(df_ohlc_cleaned))\n",
        "\n",
        "            # Obtener los id_event que cumplen con las condiciones en ambas tablas\n",
        "            cleaned_events_vista = df_vista_cleaned['id_event'].unique()\n",
        "            cleaned_events_ohlc = df_ohlc_cleaned['id_event'].unique()\n",
        "\n",
        "            # Encontrar la intersección de id_event entre ambas tablas\n",
        "            common_events = set(cleaned_events_vista).intersection(set(cleaned_events_ohlc))\n",
        "\n",
        "            # Filtrar ambas tablas para mantener solo los registros con id_event comunes\n",
        "            df_vista_final = df_vista_cleaned[df_vista_cleaned['id_event'].isin(common_events)]\n",
        "            df_ohlc_final = df_ohlc_cleaned[df_ohlc_cleaned['id_event'].isin(common_events)]\n",
        "\n",
        "            # Calcular el PnL_percent para cada evento en OHLCData\n",
        "            df_ohlc_final = self.calculate_pnl(df_ohlc_final)\n",
        "\n",
        "            # Fusionar la columna pnl en vista_datos_completos\n",
        "            df_merged = df_vista_final.merge(\n",
        "                df_ohlc_final[['id_event', 'pnl_percent']].drop_duplicates('id_event'),\n",
        "                on='id_event',\n",
        "                how='left'\n",
        "            )\n",
        "\n",
        "            # Guardar la tabla final\n",
        "            self.cleaned_dataframes['vista_datos_completos'] = df_merged\n",
        "\n",
        "            print(\"Tabla vista_datos_completos filtrada, limpia y con % pnl guardada correctamente.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error al analizar las tablas: {e}\")\n",
        "\n",
        "    def filter_vista_datos_completos(self, df):\n",
        "        \"\"\"\n",
        "        Filtra la tabla vista_datos_completos según las condiciones:\n",
        "        - precio < 20\n",
        "        - float_shares < 40000000\n",
        "        - market_cap < 300000000\n",
        "        \"\"\"\n",
        "        try:\n",
        "            required_columns = ['precio', 'float_shares', 'market_cap']\n",
        "            if all(column in df.columns for column in required_columns):\n",
        "                filtered_df = df[(df['precio'] < 15) &\n",
        "                                 (df['float_shares'] < 40000000) &\n",
        "                                 (df['market_cap'] < 500000000)]\n",
        "                print(\"vista_datos_completos filtrada según las condiciones especificadas.\")\n",
        "                return filtered_df\n",
        "            else:\n",
        "                print(\"Advertencia: No se encontraron todas las columnas requeridas para el filtrado.\")\n",
        "                return df\n",
        "        except Exception as e:\n",
        "            print(f\"Error al filtrar vista_datos_completos: {e}\")\n",
        "            return df\n",
        "\n",
        "    def calculate_pnl(self, df_ohlc):\n",
        "        \"\"\"\n",
        "        Calcula el % PnL para cada evento en el DataFrame OHLCData.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Definir rangos para stop loss y take profit (en porcentaje)\n",
        "            stop_loss_percentage = 0.05  # 3%\n",
        "            take_profit_percentage = 0.04  # 4%\n",
        "\n",
        "            # Lista para almacenar los resultados del PnL\n",
        "            pnl_results = []\n",
        "\n",
        "            # Iterar sobre cada evento único\n",
        "            for event_id in df_ohlc['id_event'].unique():\n",
        "                # Filtrar los datos OHLC para el evento actual\n",
        "                ohlc_data = df_ohlc[df_ohlc['id_event'] == event_id]\n",
        "\n",
        "                if ohlc_data.empty:\n",
        "                    continue  # Saltar eventos sin datos\n",
        "\n",
        "                # Obtener el precio de apertura del evento\n",
        "                open_price = ohlc_data.iloc[0]['open']\n",
        "\n",
        "                # Inicializar stop loss y take profit\n",
        "                stop_loss_price = open_price * (1 - stop_loss_percentage)\n",
        "                stop_loss_adjusted = open_price * 0.10  # Ajuste si sube 20%\n",
        "                take_profit_price = ohlc_data['high'].max()  # Tomar el máximo como take profit\n",
        "\n",
        "                # Determinar el resultado del trade en porcentaje\n",
        "                exit_price = take_profit_price  # Default\n",
        "\n",
        "                for _, row in ohlc_data.iterrows():\n",
        "                    if row['high'] >= open_price * 1.20:\n",
        "                        stop_loss_price = stop_loss_adjusted  # Ajustar stop loss dinámicamente\n",
        "\n",
        "                    if row['low'] <= stop_loss_price:\n",
        "                        exit_price = stop_loss_price\n",
        "                        break\n",
        "                    if row['high'] >= take_profit_price:\n",
        "                        exit_price = take_profit_price\n",
        "                        break\n",
        "\n",
        "                # Calcular el PnL final\n",
        "                pnl_percent = ((exit_price - open_price) / open_price) * 100\n",
        "\n",
        "                # Guardar resultados para cada evento\n",
        "                pnl_results.append({\n",
        "                    'id_event': event_id,\n",
        "                    'pnl_percent': pnl_percent\n",
        "                })\n",
        "\n",
        "            # Convertir los resultados a un DataFrame\n",
        "            pnl_df = pd.DataFrame(pnl_results)\n",
        "\n",
        "            return pnl_df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error al calcular el % PnL: {e}\")\n",
        "            return df_ohlc\n",
        "\n",
        "    def save_cleaned_data_to_hdf5(self, file_path):\n",
        "        try:\n",
        "            if self.cleaned_dataframes:\n",
        "                # Verificar si el archivo ya existe\n",
        "                if os.path.exists(file_path):\n",
        "                    overwrite = input(f\"El archivo {file_path} ya existe. ¿Desea sobrescribirlo? (s/n): \").strip().lower()\n",
        "                    if overwrite != 's':\n",
        "                        new_file_path = input(\"Introduce la nueva ruta del archivo HDF5: \")\n",
        "                        file_path = new_file_path\n",
        "\n",
        "                # Forzar el cierre del archivo si está abierto\n",
        "                try:\n",
        "                    import tables\n",
        "                    if tables.is_hdf5_file(file_path):\n",
        "                        with pd.HDFStore(file_path, mode='r') as store:\n",
        "                            store.close()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                # Guardar los DataFrames en el archivo HDF5\n",
        "                with pd.HDFStore(file_path, mode='w') as store:\n",
        "                    for table_name, df in self.cleaned_dataframes.items():\n",
        "                        store.put(table_name, df)\n",
        "                        print(f\"Tabla '{table_name}' guardada en {file_path}\")\n",
        "            else:\n",
        "                print(\"No hay datos limpios para guardar.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error al guardar los DataFrames en HDF5: {e}\")\n",
        "\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Crear una instancia de DatabaseAnalyzer\n",
        "analyzer = DatabaseAnalyzer()\n",
        "\n",
        "# Establecer la conexión a la base de datos\n",
        "analyzer.get_db_connection()\n",
        "\n",
        "# Guardar los DataFrames limpios y filtrados en un archivo HDF5\n",
        "file_path = '/content/drive/MyDrive/Proyecto_SmallCaps/BBDD/bbdd_filtrada.h5'\n",
        "analyzer.save_cleaned_data_to_hdf5(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCACD9e_s9c0",
        "outputId": "b9a8e151-e0a7-499c-a2ff-4fd69cc32040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.39)\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.12.1)\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py) (1.26.4)\n",
            "Requirement already satisfied: google-auth==2.38.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.38.0)\n",
            "Requirement already satisfied: ipykernel==6.17.1 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.17.1)\n",
            "Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (8.8.0)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.5 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.5.5)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.2.2)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.32.3)\n",
            "Requirement already satisfied: tornado==6.4.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.4.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0->google-colab) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0->google-colab) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0->google-colab) (4.9)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.0.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.67.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython==7.34.0->google-colab)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (4.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (5.7.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.5->google-colab) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->google-colab) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->google-colab) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2025.1.31)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.5->google-colab) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.5->google-colab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.5->google-colab) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.5->google-colab) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.38.0->google-colab) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->ipyparallel==8.8.0->google-colab) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook==6.5.5->google-colab) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.5->google-colab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.5->google-colab) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (25.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.23.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.5->google-colab) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.3.1)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m846.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymysql, jedi\n",
            "Successfully installed jedi-0.19.2 pymysql-1.1.1\n",
            "Mounted at /content/drive\n",
            "Introduce el host de la base de datos: librobot.org\n",
            "Introduce el usuario de la base de datos: faq2108\n",
            "Introduce la contraseña de la base de datos: ··········\n",
            "Introduce el nombre de la base de datos: smallcaps\n",
            "Conexión establecida correctamente.\n",
            "Valores nulos antes de la limpieza (vista_datos_completos):\n",
            "ticker            0\n",
            "id_event          0\n",
            "fecha             0\n",
            "percent_var       0\n",
            "ratio_vol         0\n",
            "precio            3\n",
            "volumen           0\n",
            "spread          133\n",
            "insercion         0\n",
            "anterior          0\n",
            "apertura          0\n",
            "float_shares    431\n",
            "exchange        238\n",
            "country         238\n",
            "avg_volume      238\n",
            "shs_outstand    252\n",
            "market_cap      240\n",
            "inst_own        238\n",
            "short_float     441\n",
            "dtype: int64\n",
            "Valores nulos después de la limpieza (vista_datos_completos):\n",
            "ticker            0\n",
            "id_event          0\n",
            "fecha             0\n",
            "percent_var       0\n",
            "ratio_vol         0\n",
            "precio            0\n",
            "volumen           0\n",
            "spread          116\n",
            "insercion         0\n",
            "anterior          0\n",
            "apertura          0\n",
            "float_shares      0\n",
            "exchange          0\n",
            "country           0\n",
            "avg_volume        0\n",
            "shs_outstand      0\n",
            "market_cap        0\n",
            "inst_own          0\n",
            "short_float      12\n",
            "dtype: int64\n",
            "vista_datos_completos filtrada según las condiciones especificadas.\n",
            "Valores nulos antes de la limpieza (OHLCData):\n",
            "id_ohlc     0\n",
            "id_event    0\n",
            "date        0\n",
            "open        0\n",
            "high        0\n",
            "low         0\n",
            "close       0\n",
            "volume      0\n",
            "synced      0\n",
            "dtype: int64\n",
            "Valores nulos después de la limpieza (OHLCData):\n",
            "id_ohlc     0\n",
            "id_event    0\n",
            "date        0\n",
            "open        0\n",
            "high        0\n",
            "low         0\n",
            "close       0\n",
            "volume      0\n",
            "synced      0\n",
            "dtype: int64\n",
            "Tabla vista_datos_completos filtrada, limpia y con % pnl guardada correctamente.\n",
            "El archivo /content/drive/MyDrive/Proyecto_SmallCaps/BBDD/bbdd_filtrada.h5 ya existe. ¿Desea sobrescribirlo? (s/n): s\n",
            "Tabla 'vista_datos_completos' guardada en /content/drive/MyDrive/Proyecto_SmallCaps/BBDD/bbdd_filtrada.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para verificacion:\n",
        "# Ruta al archivo HDF5\n",
        "df = pd.read_hdf('/content/drive/MyDrive/Proyecto_SmallCaps/BBDD/bbdd_filtrada.h5', key='vista_datos_completos')\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "khaDRHvucv2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db8ff77-dfb2-4b1c-c714-4c07247d255b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ticker  id_event               fecha  percent_var  ratio_vol  precio  \\\n",
            "0   GNLN         1 2025-01-15 14:33:00        10.26       3.52    1.72   \n",
            "1   VCIG         3 2025-01-15 14:38:49        18.97       3.45    2.32   \n",
            "2   LAES         4 2025-01-15 14:39:28        23.22       3.44    4.51   \n",
            "3   XRTX         7 2025-01-15 14:55:55       -35.43       3.25    0.82   \n",
            "4   QLGN         8 2025-01-15 14:56:32        -2.47       3.24    3.95   \n",
            "\n",
            "    volumen  spread           insercion  anterior  apertura  float_shares  \\\n",
            "0        27    0.08 2025-01-15 14:32:53      1.56      1.56     1980000.0   \n",
            "1       312    0.03 2025-01-15 14:38:42      1.95      2.02     7600000.0   \n",
            "2  13800000    0.01 2025-01-15 14:39:21      3.66      3.97    22110000.0   \n",
            "3       150    0.08 2025-01-15 14:55:48      1.27      1.22     3370000.0   \n",
            "4         4    0.55 2025-01-15 14:56:25      4.05      4.02      690000.0   \n",
            "\n",
            "  exchange      country  avg_volume  shs_outstand   market_cap  inst_own  \\\n",
            "0     NASD          USA   1180000.0     1980000.0    3090000.0    0.0375   \n",
            "1     NASD     Malaysia   7010000.0    38030000.0   42150000.0    0.0003   \n",
            "2     NASD  Switzerland  38610000.0    22730000.0  357610000.0    0.1855   \n",
            "3     NASD       Canada    115510.0     3480000.0    4420000.0    0.0559   \n",
            "4     NASD          USA     98330.0      740000.0    2980000.0    0.0171   \n",
            "\n",
            "   short_float  pnl_percent  \n",
            "0       0.0167    12.531328  \n",
            "1       0.1295    19.801980  \n",
            "2       0.5944    -5.000000  \n",
            "3       0.0007    -5.000000  \n",
            "4       0.1266     4.987531  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge PnL con vista de datos completos..."
      ],
      "metadata": {
        "id": "HmJc4OSBGnKP"
      }
    }
  ]
}